{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\"\n",
    "import json\n",
    "import pickle\n",
    "import io\n",
    "import pandas as pd\n",
    "from dataclasses import asdict\n",
    "from backdoors import data, patterns, poison, utils, checkpoint_dir\n",
    "from backdoors.data import load_cifar10, Data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import einops\n",
    "import jax\n",
    "from jax import numpy as jnp\n",
    "from flax.training import train_state\n",
    "import optax\n",
    "import chex\n",
    "import flax\n",
    "from flax import linen as nn\n",
    "from typing import Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "import sympy\n",
    "from jax import random\n",
    "from collections import namedtuple\n",
    "from time import time\n",
    "\n",
    "import orbax.checkpoint\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from backdoors import image_utils\n",
    "from backdoors import module_path, checkpoint_dir, train, paths\n",
    "from backdoors.train import TrainState, Metrics, model, tx, \\\n",
    "    accuracy, train_step, init_train_state\n",
    "from backdoors.models import CNN\n",
    "from meta_transformer.data import load_pair_of_models, data_iterator\n",
    "from tqdm import tqdm\n",
    "rng = random.PRNGKey(0)\n",
    "\n",
    "checkpointer = orbax.checkpoint.PyTreeCheckpointer()\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 5\n",
    "\n",
    "#train_data, _ = load_cifar10()\n",
    "#cifar10_train, cifar10_test = load_cifar10()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load batch\n",
    "def load_batch(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        batch = pickle.load(f)\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_batches(datadir):\n",
    "    \"\"\"Load all batches from a directory\"\"\"\n",
    "    for entry in os.scandir(datadir):\n",
    "        if entry.name.startswith('checkpoints'):\n",
    "            yield load_batch(entry.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_models(idxs: Sequence[int], dir: str, max_workers: int = 1):\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        out = executor.map(partial(load_model, dir=dir), idxs)\n",
    "    models, info = [list(x) for x in zip(*out)]\n",
    "    return models, info"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meta-models",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
